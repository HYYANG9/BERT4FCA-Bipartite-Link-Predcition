{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a217b485-2c77-4334-b631-9d5c1557e077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from math import sqrt as msqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "import torch\n",
    "import torch.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import Adadelta\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846cd6e8-fa3a-40f6-95db-57ef1f98f8b2",
   "metadata": {},
   "source": [
    "# BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e71abe12-dd27-4fd4-89a3-faf602558f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the maximum of length of sequences\n",
    "max_len = 43 * 2 + 3\n",
    "# the number of tokens (objects or attributes)\n",
    "max_vocab = 473\n",
    "# the maximum number of masked tokens\n",
    "max_pred = 4\n",
    "# dimension of key, values. the dimension of query and key are the same \n",
    "d_k = d_v = 64\n",
    "# dimension of embedding\n",
    "d_model = 768  # n_heads * d_k\n",
    "# dimension of hidden layers\n",
    "d_ff = d_model * 4\n",
    "\n",
    "# number of heads\n",
    "n_heads = 12\n",
    "# number of encoders\n",
    "n_layers = 6\n",
    "# the number of input setences\n",
    "n_segs = 2\n",
    "\n",
    "p_dropout = .1\n",
    "\n",
    "#80% the chosen token is replaced by [mask], 10% is replaced by a random token, 10% do nothing\n",
    "p_mask = .8\n",
    "p_replace = .1\n",
    "p_do_nothing = 1 - p_mask - p_replace\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250449b-7ba4-4997-bf60-7cf5c9b21a55",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$\n",
    "\\displaylines{\n",
    "\\operatorname{GELU}(x)=x P(X \\leq x)= x \\Phi(x)=x \\cdot \\frac{1}{2}[1+\\operatorname{erf}(x / \\sqrt{2})] \\\\\n",
    " or \\\\\n",
    "0.5 x\\left(1+\\tanh \\left[\\sqrt{2 / \\pi}\\left( x+ 0.044715 x^{3}\\right)\\right]\\right)\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2afabc0f-b617-4ada-980c-4ab6374e2741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    '''\n",
    "    Two way to implements GELU:\n",
    "    0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "    or\n",
    "    0.5 * x * (1. + torch.erf(torch.sqrt(x, 2))) \n",
    "    '''\n",
    "    return .5 * x * (1. + torch.erf(x / msqrt(2.)))\n",
    "\n",
    "#  create a mask tensor to identify the padding tokens in a batch of sequences\n",
    "def get_pad_mask(tokens, pad_idx=0):\n",
    "    '''\n",
    "    suppose index of [PAD] is zero in word2idx\n",
    "    the size of input tokens is [batch, seq_len]\n",
    "    '''\n",
    "    batch, seq_len = tokens.size()\n",
    "    pad_mask = tokens.data.eq(pad_idx).unsqueeze(1) #.unsqueeze(1) adds a dimension and turns it to column vectors\n",
    "    pad_mask = pad_mask.expand(batch, seq_len, seq_len)\n",
    "    \n",
    "    # The size of pad_mask is [batch, seq_len, seq_len]\n",
    "    # The resulting tensor has True where padding tokens are located and False elsewhere.\n",
    "    \n",
    "    # print(f'the shape of pad_mask is {pad_mask.shape}')\n",
    "    return pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbdfc5f8-5107-4d28-ae6f-e3cf435ff501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# process input tokens to dense vectors before passing them to encoder.\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.seg_emb = nn.Embedding(n_segs, d_model)\n",
    "        '''\n",
    "        convert indices into vector embeddings.\n",
    "        max_vocab can be replaced by formal context object vectors or attribute vectors\n",
    "        '''\n",
    "        self.word_emb = nn.Embedding(max_vocab, d_model)\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        '''\n",
    "        x: [batch, seq_len]\n",
    "        '''\n",
    "        word_enc = self.word_emb(x)\n",
    "        \n",
    "        '''\n",
    "        maybe positional embedding can be deleted\n",
    "        '''\n",
    "        # # positional embedding\n",
    "        # pos = torch.arange(x.shape[1], dtype=torch.long, device=device) # .long: round down\n",
    "        # pos = pos.unsqueeze(0).expand_as(x) # the shape is [1, seq_len]\n",
    "        # pos_enc = self.pos_emb(pos)\n",
    "\n",
    "        seg_enc = self.seg_emb(seg)\n",
    "        x = self.norm(word_enc + seg_enc)\n",
    "        return self.dropout(x)\n",
    "        # return: [batch, seq_len, d_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918d4e8-120a-475a-8347-9b2819931e9d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\operatorname{Attention}(Q, K, V) = \\operatorname{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{MultiHead}(Q, K, V) &= \\operatorname{Concat}(\\text{head}_1, \\text{head}_2, \\dots, \\text{head}_h)W^O \\\\\n",
    "\\text{where } \\text{head}_i &= \\operatorname{Attention}(QW^Q_i, KW^K_i, VW^V_i)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3e04a1a-6b7a-4b33-a880-a04b4c603f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2) / msqrt(d_k))\n",
    "        # scores: [batch, n_heads, seq_len, seq_len]\n",
    "        # fill the positions in the scores tensor where the attn_mask is True with a very large negative value (-1e9). \n",
    "        scores.masked_fill_(attn_mask, -1e9)\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        # context: [batch, n_heads, seq_len, d_v]\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        '''\n",
    "        Q, K, V: [batch, seq_len, d_model]\n",
    "        attn_mask: [batch, seq_len, seq_len]\n",
    "        '''\n",
    "        batch = Q.size(0)\n",
    "        '''\n",
    "        split Q, K, V to per head formula: [batch, seq_len, n_heads, d_k]\n",
    "        Convenient for matrix multiply opearation later\n",
    "        q, k, v: [batch, n_heads, seq_len, d_k or d_v]\n",
    "        '''\n",
    "        per_Q = self.W_Q(Q).view(batch, -1, n_heads, d_k).transpose(1, 2)\n",
    "        per_K = self.W_K(K).view(batch, -1, n_heads, d_k).transpose(1, 2)\n",
    "        per_V = self.W_V(V).view(batch, -1, n_heads, d_v).transpose(1, 2)\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n",
    "        # context: [batch, n_heads, seq_len, d_v]\n",
    "        context = ScaledDotProductAttention()(per_Q, per_K, per_V, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch, -1, n_heads * d_v)\n",
    "\n",
    "        # output: [batch, seq_len, d_model]\n",
    "        output = self.fc(context)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a5e55b-316c-4f61-9cd2-b2a4e345c9c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$\\operatorname{FFN}(x)=\\operatorname{GELU}(xW_1+b_1)W_2+b_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6778e9cd-6b44-4da2-bb4d-13be02ba6e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "        self.gelu = gelu\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68c1f620-2e47-45d3-86c6-e6d3c57afde5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.enc_attn = MultiHeadAttention()\n",
    "        self.ffn = FeedForwardNetwork()\n",
    "\n",
    "    def forward(self, x, pad_mask):\n",
    "        '''\n",
    "        pre-norm\n",
    "        see more detail in https://openreview.net/pdf?id=B1x8anVFPr\n",
    "\n",
    "        x: [batch, seq_len, d_model]\n",
    "        '''\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.enc_attn(x, x, x, pad_mask) + residual\n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ffn(x)\n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de7edf80-fca4-4bf1-b8c4-84518a76d28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next sentence prediction\n",
    "# pooled representation of the entire sequence as the [CLS] token representation.\n",
    "'''\n",
    "The full connected linear layer improve the result while making the model harder to train.\n",
    "'''\n",
    "class Pooler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pooler, self).__init__()\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: [batch, d_model] (first place output)\n",
    "        '''\n",
    "        x = self.fc(x)\n",
    "        x = self.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec84a485-9754-4307-ab05-b896718e330d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, n_layers):\n",
    "        super(BERT, self).__init__()\n",
    "        self.embedding = Embeddings()\n",
    "        self.encoders = nn.ModuleList([\n",
    "            EncoderLayer() for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        self.pooler = Pooler()\n",
    "        \n",
    "        # next sentence prediction. output is 0 or 1.\n",
    "        self.next_cls = nn.Linear(d_model, 2)\n",
    "        self.gelu = gelu\n",
    "        \n",
    "        # Sharing weight between some fully connect layer, this will make training easier.\n",
    "        shared_weight = self.pooler.fc.weight\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.fc.weight = shared_weight\n",
    "\n",
    "        shared_weight = self.embedding.word_emb.weight\n",
    "        self.word_classifier = nn.Linear(d_model, max_vocab, bias=False)\n",
    "        self.word_classifier.weight = shared_weight\n",
    "\n",
    "    def forward(self, tokens, segments, masked_pos):\n",
    "        output = self.embedding(tokens, segments)\n",
    "        enc_self_pad_mask = get_pad_mask(tokens)\n",
    "        for layer in self.encoders:\n",
    "            output = layer(output, enc_self_pad_mask)\n",
    "        # output: [batch, max_len, d_model]\n",
    "\n",
    "        # NSP Task\n",
    "        '''\n",
    "        Extracting the [CLS] token representation, \n",
    "        passing it through the pooler, \n",
    "        and making predictions.\n",
    "        '''\n",
    "        hidden_pool = self.pooler(output[:, 0]) # only the [CLS] token\n",
    "        logits_cls = self.next_cls(hidden_pool)\n",
    "\n",
    "        # Masked Language Model Task\n",
    "        '''\n",
    "        extracting representations of masked positions, \n",
    "        passing them through a fully connected layer, \n",
    "        applying the GELU activation function, \n",
    "        and making predictions using the word classifier\n",
    "        '''\n",
    "        # masked_pos: [batch, max_pred] -> [batch, max_pred, d_model]\n",
    "        masked_pos = masked_pos.unsqueeze(-1).expand(-1, -1, d_model)\n",
    "\n",
    "        # h_masked: [batch, max_pred, d_model]\n",
    "        h_masked = torch.gather(output, dim=1, index=masked_pos)\n",
    "        h_masked = self.gelu(self.fc(h_masked))\n",
    "        logits_lm = self.word_classifier(h_masked)\n",
    "        # logits_lm: [batch, max_pred, max_vocab]\n",
    "        # logits_cls: [batch, 2]\n",
    "\n",
    "        return logits_cls, logits_lm, hidden_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9177c2-dcb1-4500-bf67-e0f7ee0d286a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14012f5d-fc34-42ba-a496-1bd61287973d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n"
     ]
    }
   ],
   "source": [
    "def process_concepts_from_file(filename) :\n",
    "    extents = []\n",
    "\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Split the line based on four blank spaces\n",
    "            parts = line.split('    ')\n",
    "\n",
    "            # Extract the right sequence (assuming it's the second part after splitting)\n",
    "            if len(parts) >= 2:\n",
    "                extent = parts[1].strip()\n",
    "                extents.append(extent)\n",
    "\n",
    "    object_list = list(set(\" \".join(extents).split()))\n",
    "    sorted_object_list = sorted(map(int, object_list))\n",
    "\n",
    "    print(len(object_list))\n",
    "    # Create the object2idx dictionary\n",
    "    object2idx = {str(obj): idx + 1  for idx, obj in enumerate(sorted_object_list)}\n",
    "    sorted_object_list = list(map(str, sorted_object_list ))\n",
    "\n",
    "    special_tokens = {'[PAD]': max_vocab - 4, '[CLS]': max_vocab - 3, '[SEP]': max_vocab - 2, '[MASK]': max_vocab - 1}\n",
    "\n",
    "    object2idx.update(special_tokens)\n",
    "    # print(len(object2idx))\n",
    "\n",
    "    idx2object = {idx: object for object, idx in object2idx.items()}\n",
    "    vocab_size = len(object2idx)\n",
    "    # assert len(object2idx) == len(idx2object)\n",
    "\n",
    "    extent_token_list = []\n",
    "    for extent in extents:\n",
    "        extent_token_list.append([\n",
    "            object2idx[s] for s in extent.split()\n",
    "        ])\n",
    "        \n",
    "    return extent_token_list, object2idx, idx2object\n",
    "\n",
    "extent_token_list, object2idx, idx2object = process_concepts_from_file('BMS-POS-with-missing-part-renumbered_concepts.txt')\n",
    "extent_token_list_new, object2idx2, idx2object2 = process_concepts_from_file('BMS-POS-renumbered_concepts.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe5d1fe4-fffa-4d8f-838b-4ea8e3686507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "maxlen = 0\n",
    "for extent in extent_token_list :\n",
    "    maxlen = max(len(extent), maxlen)\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f03f47b-2af5-4b2f-90fa-eb9939803580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# padding the token lists to have the same length.\n",
    "def padding(ids, n_pads, pad_symb=0):\n",
    "    return ids.extend([pad_symb for _ in range(n_pads)])\n",
    "\n",
    "def masking_procedure(cand_pos, input_ids, masked_symb='[MASK]'):\n",
    "    masked_pos = []\n",
    "    masked_tokens = []\n",
    "    for pos in cand_pos:\n",
    "        masked_pos.append(pos)\n",
    "        masked_tokens.append(input_ids[pos])\n",
    "        if random.random() < p_mask:\n",
    "            input_ids[pos] = masked_symb\n",
    "        elif random.random() > (p_mask + p_replace):\n",
    "            rand_word_idx = random.randint(0, max_vocab - 4)\n",
    "            input_ids[pos] = rand_word_idx\n",
    "\n",
    "    return masked_pos, masked_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2a28666-9619-4be9-b41d-287b585b9d21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135183\n"
     ]
    }
   ],
   "source": [
    "def get_neighbor_samples(extents) :\n",
    "    n = len(extents)\n",
    "    samples = []\n",
    "\n",
    "    dep = np.zeros(shape = (n, n), dtype = np.int32)\n",
    "    neighbor = np.zeros(shape = (n, n), dtype = np.int32)\n",
    "\n",
    "    for i in range(n) :\n",
    "        for j in range(i + 1, n) :\n",
    "            if set(extents[i]).issubset(set(extents[j])) :\n",
    "                dep[i][j] = 1\n",
    "            if set(extents[j]).issubset(set(extents[i])) :\n",
    "                dep[j][i] = 1\n",
    "\n",
    "    for i in range(n) :\n",
    "        se = set([])\n",
    "        for j in range(n) :\n",
    "            if j != i :\n",
    "                if dep[j][i] == 1 :\n",
    "                    rep = False\n",
    "                    lst = list(se)\n",
    "                    for idk, k in enumerate(lst) :\n",
    "                        if dep[k][j] :\n",
    "                            se.remove(k)\n",
    "                            se.add(j)\n",
    "                            rep = True\n",
    "                        if dep[j][k] :\n",
    "                            rep = True\n",
    "                    if not rep :\n",
    "                        se.add(j)\n",
    "\n",
    "        for j in range(n) :\n",
    "            if j in se :\n",
    "                samples.append([i, j, True])\n",
    "            elif random.random() < 0.0018 :\n",
    "                samples.append([i, j, False])\n",
    "        \n",
    "    return samples\n",
    "\n",
    "all_samples = get_neighbor_samples(extent_token_list)\n",
    "print(len(all_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c7bbee8-a2a9-4611-9ad6-7d34243dbf6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "nf = 0\n",
    "nt = 0\n",
    "for sample in all_samples :\n",
    "    extent1, extent2, label = sample\n",
    "    if label == False :\n",
    "        nf += 1\n",
    "    else :\n",
    "        nt += 1\n",
    "\n",
    "new_all_samples = []\n",
    "droprate = nt / nf\n",
    "\n",
    "for sample in all_samples :\n",
    "    extent1, extent2, label = sample\n",
    "    if label == True :\n",
    "        new_all_samples.append([extent1, extent2, True])\n",
    "    elif random.random() < droprate :\n",
    "        new_all_samples.append([extent1, extent2, False])\n",
    "        \n",
    "with open('pretrain_samples.pkl', 'wb') as f:\n",
    "    pickle.dump(new_all_samples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14bc0bc7-e3e1-47c6-8db5-203715c310d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pretrain_samples.pkl', 'rb') as f:\n",
    "    all_samples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5afe0534-d54a-4aa2-9aaa-384813468cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data(extents, all_samples, word2idx, n_data, num_per_sample = 120):\n",
    "    batch_data = []\n",
    "    positive = negative = 0\n",
    "    max_len = 0\n",
    "    len_sentences = len(extents)\n",
    "    for extent in extents :\n",
    "        max_len = max(max_len, len(extent))\n",
    "    max_len = max_len * 2 + 3\n",
    "        \n",
    "    for sample in all_samples :\n",
    "        \n",
    "        tokens_a_idx = sample[0]\n",
    "        tokens_b_idx = sample[1]\n",
    "        tokens_a = extent_token_list[tokens_a_idx]\n",
    "        tokens_b = extent_token_list[tokens_b_idx]\n",
    "             \n",
    "        input_ids = [word2idx['[CLS]']] + tokens_a + [word2idx['[SEP]']] + tokens_b + [word2idx['[SEP]']]\n",
    "        segment_ids = [0 for i in range(\n",
    "            1 + len(tokens_a) + 1)] + [1 for i in range(1 + len(tokens_b))]\n",
    "\n",
    "        # Determines the number of positions to mask (n_pred) based on the input sequence length.\n",
    "        n_pred = min(max_pred, max(1, int(len(input_ids) * .15)))\n",
    "        cand_pos = [i for i, token in enumerate(input_ids)\n",
    "                    if token != word2idx['[CLS]'] and token != word2idx['[SEP]']] #exclude special tokens.\n",
    "\n",
    "        # shuffle all candidate position index, to sampling maksed position from first n_pred\n",
    "        masked_pos, masked_tokens = masking_procedure(\n",
    "            cand_pos[:n_pred], input_ids, word2idx['[MASK]'])\n",
    "\n",
    "        # zero padding for tokens to ensure that the input sequences and segment IDs have the maximum sequence length\n",
    "        padding(input_ids, max_len - len(input_ids))\n",
    "        # print(\"the size of input_ids is \" ,len(input_ids))\n",
    "        padding(segment_ids, max_len - len(segment_ids))\n",
    "        # print(\"the size of segment_ids is \" ,len(segment_ids))\n",
    "\n",
    "        # zero padding for mask\n",
    "        if max_pred > n_pred:\n",
    "            n_pads = max_pred - n_pred\n",
    "            padding(masked_pos, n_pads)\n",
    "            padding(masked_tokens, n_pads)\n",
    "\n",
    "        # Creating Batch Data:\n",
    "        batch_data.append(\n",
    "            [input_ids, segment_ids, masked_tokens, masked_pos, sample[2]])\n",
    "\n",
    "    random.shuffle(batch_data)\n",
    "    print(len(batch_data))\n",
    "    return batch_data\n",
    "\n",
    "\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, input_ids, segment_ids, masked_tokens, masked_pos, is_next):\n",
    "        super(BERTDataset, self).__init__()\n",
    "        self.input_ids = input_ids\n",
    "        self.segment_ids = segment_ids\n",
    "        self.masked_tokens = masked_tokens\n",
    "        self.masked_pos = masked_pos\n",
    "        self.is_next = is_next\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.segment_ids[index], self.masked_tokens[index], self.masked_pos[index], self.is_next[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5b5fd-3776-4641-baa3-d82a8c496007",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pre-Train BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3a030f9-caff-4a5e-8763-9a061fbabe3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 44 \n",
    "lr = 1.9e-5\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40521dbb-258b-4a9e-a94f-859e4a6836a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135183\n",
      "Entering training process...\n",
      "Epoch:0 Batch:0\t loss: 44.841179\n",
      "Epoch:0 Batch:500\t loss: 1.314326\n",
      "Epoch:0 Batch:1000\t loss: 1.150195\n",
      "Epoch:0 Batch:1500\t loss: 0.916032\n",
      "Epoch:0 Batch:2000\t loss: 0.783643\n",
      "Epoch:0 Batch:2500\t loss: 0.750319\n",
      "Epoch:0 Batch:3000\t loss: 0.682847\n",
      "Epoch:1 Batch:0\t loss: 0.565573\n",
      "Epoch:1 Batch:500\t loss: 0.484101\n",
      "Epoch:1 Batch:1000\t loss: 0.768395\n",
      "Epoch:1 Batch:1500\t loss: 0.567375\n",
      "Epoch:1 Batch:2000\t loss: 0.315872\n",
      "Epoch:1 Batch:2500\t loss: 0.627168\n",
      "Epoch:1 Batch:3000\t loss: 0.613287\n",
      "Epoch:2 Batch:0\t loss: 0.368057\n",
      "Epoch:2 Batch:500\t loss: 0.404705\n",
      "Epoch:2 Batch:1000\t loss: 0.535162\n",
      "Epoch:2 Batch:1500\t loss: 0.629393\n",
      "Epoch:2 Batch:2000\t loss: 0.430506\n",
      "Epoch:2 Batch:2500\t loss: 0.366674\n",
      "Epoch:2 Batch:3000\t loss: 0.457301\n",
      "Epoch:3 Batch:0\t loss: 0.407340\n",
      "Epoch:3 Batch:500\t loss: 0.388044\n",
      "Epoch:3 Batch:1000\t loss: 0.223909\n",
      "Epoch:3 Batch:1500\t loss: 0.202169\n",
      "Epoch:3 Batch:2000\t loss: 0.318845\n",
      "Epoch:3 Batch:2500\t loss: 0.231870\n",
      "Epoch:3 Batch:3000\t loss: 0.354200\n",
      "Epoch:4 Batch:0\t loss: 0.426291\n",
      "Epoch:4 Batch:500\t loss: 0.368868\n",
      "Epoch:4 Batch:1000\t loss: 0.299018\n",
      "Epoch:4 Batch:1500\t loss: 0.401807\n",
      "Epoch:4 Batch:2000\t loss: 0.480326\n",
      "Epoch:4 Batch:2500\t loss: 0.330730\n",
      "Epoch:4 Batch:3000\t loss: 0.542660\n",
      "Epoch:5 Batch:0\t loss: 0.337151\n",
      "Epoch:5 Batch:500\t loss: 0.706122\n",
      "Epoch:5 Batch:1000\t loss: 0.296985\n",
      "Epoch:5 Batch:1500\t loss: 0.295265\n",
      "Epoch:5 Batch:2000\t loss: 0.263819\n",
      "Epoch:5 Batch:2500\t loss: 0.228913\n",
      "Epoch:5 Batch:3000\t loss: 0.297321\n",
      "Epoch:6 Batch:0\t loss: 0.238110\n",
      "Epoch:6 Batch:500\t loss: 0.229160\n",
      "Epoch:6 Batch:1000\t loss: 0.323104\n",
      "Epoch:6 Batch:1500\t loss: 0.255867\n",
      "Epoch:6 Batch:2000\t loss: 0.371279\n",
      "Epoch:6 Batch:2500\t loss: 0.258496\n",
      "Epoch:6 Batch:3000\t loss: 0.612481\n",
      "Epoch:7 Batch:0\t loss: 0.191207\n",
      "Epoch:7 Batch:500\t loss: 0.273676\n",
      "Epoch:7 Batch:1000\t loss: 0.204695\n",
      "Epoch:7 Batch:1500\t loss: 0.245027\n",
      "Epoch:7 Batch:2000\t loss: 0.184223\n",
      "Epoch:7 Batch:2500\t loss: 0.457389\n",
      "Epoch:7 Batch:3000\t loss: 0.241013\n",
      "Epoch:8 Batch:0\t loss: 0.260031\n",
      "Epoch:8 Batch:500\t loss: 0.339417\n",
      "Epoch:8 Batch:1000\t loss: 0.329019\n",
      "Epoch:8 Batch:1500\t loss: 0.289224\n",
      "Epoch:8 Batch:2000\t loss: 0.191171\n",
      "Epoch:8 Batch:2500\t loss: 0.270769\n",
      "Epoch:8 Batch:3000\t loss: 0.197894\n",
      "Epoch:9 Batch:0\t loss: 0.186253\n",
      "Epoch:9 Batch:500\t loss: 0.305774\n",
      "Epoch:9 Batch:1000\t loss: 0.358345\n",
      "Epoch:9 Batch:1500\t loss: 0.277241\n",
      "Epoch:9 Batch:2000\t loss: 0.175023\n",
      "Epoch:9 Batch:2500\t loss: 0.335247\n",
      "Epoch:9 Batch:3000\t loss: 0.239183\n",
      "Epoch:10 Batch:0\t loss: 0.297203\n",
      "Epoch:10 Batch:500\t loss: 0.138951\n",
      "Epoch:10 Batch:1000\t loss: 0.267796\n",
      "Epoch:10 Batch:1500\t loss: 0.264548\n",
      "Epoch:10 Batch:2000\t loss: 0.330661\n",
      "Epoch:10 Batch:2500\t loss: 0.315841\n",
      "Epoch:10 Batch:3000\t loss: 0.317043\n",
      "Epoch:11 Batch:0\t loss: 0.149251\n",
      "Epoch:11 Batch:500\t loss: 0.243747\n",
      "Epoch:11 Batch:1000\t loss: 0.221280\n",
      "Epoch:11 Batch:1500\t loss: 0.264786\n",
      "Epoch:11 Batch:2000\t loss: 0.205406\n",
      "Epoch:11 Batch:2500\t loss: 0.184315\n",
      "Epoch:11 Batch:3000\t loss: 0.403169\n",
      "Epoch:12 Batch:0\t loss: 0.332013\n",
      "Epoch:12 Batch:500\t loss: 0.090063\n",
      "Epoch:12 Batch:1000\t loss: 0.320837\n",
      "Epoch:12 Batch:1500\t loss: 0.155321\n",
      "Epoch:12 Batch:2000\t loss: 0.260296\n",
      "Epoch:12 Batch:2500\t loss: 0.204739\n",
      "Epoch:12 Batch:3000\t loss: 0.250249\n",
      "Epoch:13 Batch:0\t loss: 0.167066\n",
      "Epoch:13 Batch:500\t loss: 0.216605\n",
      "Epoch:13 Batch:1000\t loss: 0.287177\n",
      "Epoch:13 Batch:1500\t loss: 0.205499\n",
      "Epoch:13 Batch:2000\t loss: 0.243842\n",
      "Epoch:13 Batch:2500\t loss: 0.202035\n",
      "Epoch:13 Batch:3000\t loss: 0.305220\n",
      "Epoch:14 Batch:0\t loss: 0.237662\n",
      "Epoch:14 Batch:500\t loss: 0.261109\n",
      "Epoch:14 Batch:1000\t loss: 0.168153\n",
      "Epoch:14 Batch:1500\t loss: 0.227259\n",
      "Epoch:14 Batch:2000\t loss: 0.171423\n",
      "Epoch:14 Batch:2500\t loss: 0.158598\n",
      "Epoch:14 Batch:3000\t loss: 0.138674\n",
      "Epoch:15 Batch:0\t loss: 0.219096\n",
      "Epoch:15 Batch:500\t loss: 0.241784\n",
      "Epoch:15 Batch:1000\t loss: 0.306372\n",
      "Epoch:15 Batch:1500\t loss: 0.288028\n",
      "Epoch:15 Batch:2000\t loss: 0.113453\n",
      "Epoch:15 Batch:2500\t loss: 0.253582\n",
      "Epoch:15 Batch:3000\t loss: 0.347507\n",
      "Epoch:16 Batch:0\t loss: 0.159660\n",
      "Epoch:16 Batch:500\t loss: 0.273192\n",
      "Epoch:16 Batch:1000\t loss: 0.178771\n",
      "Epoch:16 Batch:1500\t loss: 0.139956\n",
      "Epoch:16 Batch:2000\t loss: 0.208824\n",
      "Epoch:16 Batch:2500\t loss: 0.201992\n",
      "Epoch:16 Batch:3000\t loss: 0.126521\n",
      "Epoch:17 Batch:0\t loss: 0.109263\n",
      "Epoch:17 Batch:500\t loss: 0.080254\n",
      "Epoch:17 Batch:1000\t loss: 0.224438\n",
      "Epoch:17 Batch:1500\t loss: 0.198890\n",
      "Epoch:17 Batch:2000\t loss: 0.173900\n",
      "Epoch:17 Batch:2500\t loss: 0.108370\n",
      "Epoch:17 Batch:3000\t loss: 0.199823\n",
      "Epoch:18 Batch:0\t loss: 0.099675\n",
      "Epoch:18 Batch:500\t loss: 0.231270\n",
      "Epoch:18 Batch:1000\t loss: 0.055246\n",
      "Epoch:18 Batch:1500\t loss: 0.168843\n",
      "Epoch:18 Batch:2000\t loss: 0.075979\n",
      "Epoch:18 Batch:2500\t loss: 0.303036\n",
      "Epoch:18 Batch:3000\t loss: 0.200437\n",
      "Epoch:19 Batch:0\t loss: 0.172177\n",
      "Epoch:19 Batch:500\t loss: 0.205961\n",
      "Epoch:19 Batch:1000\t loss: 0.231268\n",
      "Epoch:19 Batch:1500\t loss: 0.332658\n",
      "Epoch:19 Batch:2000\t loss: 0.182995\n",
      "Epoch:19 Batch:2500\t loss: 0.262420\n",
      "Epoch:19 Batch:3000\t loss: 0.144279\n",
      "Epoch:20 Batch:0\t loss: 0.116161\n",
      "Epoch:20 Batch:500\t loss: 0.116116\n",
      "Epoch:20 Batch:1000\t loss: 0.099188\n",
      "Epoch:20 Batch:1500\t loss: 0.115829\n",
      "Epoch:20 Batch:2000\t loss: 0.223621\n",
      "Epoch:20 Batch:2500\t loss: 0.245813\n",
      "Epoch:20 Batch:3000\t loss: 0.216290\n",
      "Epoch:21 Batch:0\t loss: 0.187272\n",
      "Epoch:21 Batch:500\t loss: 0.139020\n",
      "Epoch:21 Batch:1000\t loss: 0.211889\n",
      "Epoch:21 Batch:1500\t loss: 0.117727\n",
      "Epoch:21 Batch:2000\t loss: 0.188573\n",
      "Epoch:21 Batch:2500\t loss: 0.131498\n",
      "Epoch:21 Batch:3000\t loss: 0.226469\n",
      "Epoch:22 Batch:0\t loss: 0.080989\n",
      "Epoch:22 Batch:500\t loss: 0.104415\n",
      "Epoch:22 Batch:1000\t loss: 0.153279\n",
      "Epoch:22 Batch:1500\t loss: 0.183197\n",
      "Epoch:22 Batch:2000\t loss: 0.044578\n",
      "Epoch:22 Batch:2500\t loss: 0.173736\n",
      "Epoch:22 Batch:3000\t loss: 0.142381\n",
      "Epoch:23 Batch:0\t loss: 0.114947\n",
      "Epoch:23 Batch:500\t loss: 0.102345\n",
      "Epoch:23 Batch:1000\t loss: 0.170896\n",
      "Epoch:23 Batch:1500\t loss: 0.170028\n",
      "Epoch:23 Batch:2000\t loss: 0.098477\n",
      "Epoch:23 Batch:2500\t loss: 0.079897\n",
      "Epoch:23 Batch:3000\t loss: 0.155389\n",
      "Epoch:24 Batch:0\t loss: 0.077793\n",
      "Epoch:24 Batch:500\t loss: 0.235254\n",
      "Epoch:24 Batch:1000\t loss: 0.163985\n",
      "Epoch:24 Batch:1500\t loss: 0.110949\n",
      "Epoch:24 Batch:2000\t loss: 0.080815\n",
      "Epoch:24 Batch:2500\t loss: 0.171375\n",
      "Epoch:24 Batch:3000\t loss: 0.121844\n",
      "Epoch:25 Batch:0\t loss: 0.048496\n",
      "Epoch:25 Batch:500\t loss: 0.147187\n",
      "Epoch:25 Batch:1000\t loss: 0.273964\n",
      "Epoch:25 Batch:1500\t loss: 0.114692\n",
      "Epoch:25 Batch:2000\t loss: 0.023120\n",
      "Epoch:25 Batch:2500\t loss: 0.139956\n",
      "Epoch:25 Batch:3000\t loss: 0.137464\n",
      "Epoch:26 Batch:0\t loss: 0.096532\n",
      "Epoch:26 Batch:500\t loss: 0.050352\n",
      "Epoch:26 Batch:1000\t loss: 0.075607\n",
      "Epoch:26 Batch:1500\t loss: 0.110558\n",
      "Epoch:26 Batch:2000\t loss: 0.236891\n",
      "Epoch:26 Batch:2500\t loss: 0.115510\n",
      "Epoch:26 Batch:3000\t loss: 0.057600\n",
      "Epoch:27 Batch:0\t loss: 0.104121\n",
      "Epoch:27 Batch:500\t loss: 0.028992\n",
      "Epoch:27 Batch:1000\t loss: 0.090396\n",
      "Epoch:27 Batch:1500\t loss: 0.069751\n",
      "Epoch:27 Batch:2000\t loss: 0.065966\n",
      "Epoch:27 Batch:2500\t loss: 0.068376\n",
      "Epoch:27 Batch:3000\t loss: 0.091892\n",
      "Epoch:28 Batch:0\t loss: 0.093247\n",
      "Epoch:28 Batch:500\t loss: 0.088500\n",
      "Epoch:28 Batch:1000\t loss: 0.081177\n",
      "Epoch:28 Batch:1500\t loss: 0.142568\n",
      "Epoch:28 Batch:2000\t loss: 0.059435\n",
      "Epoch:28 Batch:2500\t loss: 0.136858\n",
      "Epoch:28 Batch:3000\t loss: 0.146395\n",
      "Epoch:29 Batch:0\t loss: 0.089657\n",
      "Epoch:29 Batch:500\t loss: 0.085612\n",
      "Epoch:29 Batch:1000\t loss: 0.084275\n",
      "Epoch:29 Batch:1500\t loss: 0.202788\n",
      "Epoch:29 Batch:2000\t loss: 0.216392\n",
      "Epoch:29 Batch:2500\t loss: 0.245080\n",
      "Epoch:29 Batch:3000\t loss: 0.094454\n",
      "Epoch:30 Batch:0\t loss: 0.109008\n",
      "Epoch:30 Batch:500\t loss: 0.047676\n",
      "Epoch:30 Batch:1000\t loss: 0.106839\n",
      "Epoch:30 Batch:1500\t loss: 0.092431\n",
      "Epoch:30 Batch:2000\t loss: 0.033622\n",
      "Epoch:30 Batch:2500\t loss: 0.197001\n",
      "Epoch:30 Batch:3000\t loss: 0.121792\n",
      "Epoch:31 Batch:0\t loss: 0.138449\n",
      "Epoch:31 Batch:500\t loss: 0.131889\n",
      "Epoch:31 Batch:1000\t loss: 0.110616\n",
      "Epoch:31 Batch:1500\t loss: 0.019597\n",
      "Epoch:31 Batch:2000\t loss: 0.068619\n",
      "Epoch:31 Batch:2500\t loss: 0.042918\n",
      "Epoch:31 Batch:3000\t loss: 0.121205\n",
      "Epoch:32 Batch:0\t loss: 0.126119\n",
      "Epoch:32 Batch:500\t loss: 0.095310\n",
      "Epoch:32 Batch:1000\t loss: 0.112293\n",
      "Epoch:32 Batch:1500\t loss: 0.173685\n",
      "Epoch:32 Batch:2000\t loss: 0.049086\n",
      "Epoch:32 Batch:2500\t loss: 0.097275\n",
      "Epoch:32 Batch:3000\t loss: 0.135928\n",
      "Epoch:33 Batch:0\t loss: 0.067963\n",
      "Epoch:33 Batch:500\t loss: 0.092852\n",
      "Epoch:33 Batch:1000\t loss: 0.098715\n",
      "Epoch:33 Batch:1500\t loss: 0.186594\n",
      "Epoch:33 Batch:2000\t loss: 0.126706\n",
      "Epoch:33 Batch:2500\t loss: 0.071909\n",
      "Epoch:33 Batch:3000\t loss: 0.039095\n",
      "Epoch:34 Batch:0\t loss: 0.064759\n",
      "Epoch:34 Batch:500\t loss: 0.052072\n",
      "Epoch:34 Batch:1000\t loss: 0.111580\n",
      "Epoch:34 Batch:1500\t loss: 0.058966\n",
      "Epoch:34 Batch:2000\t loss: 0.113015\n",
      "Epoch:34 Batch:2500\t loss: 0.146824\n",
      "Epoch:34 Batch:3000\t loss: 0.061924\n",
      "Epoch:35 Batch:0\t loss: 0.266895\n",
      "Epoch:35 Batch:500\t loss: 0.057451\n",
      "Epoch:35 Batch:1000\t loss: 0.052162\n",
      "Epoch:35 Batch:1500\t loss: 0.246280\n",
      "Epoch:35 Batch:2000\t loss: 0.077388\n",
      "Epoch:35 Batch:2500\t loss: 0.105148\n",
      "Epoch:35 Batch:3000\t loss: 0.052435\n",
      "Epoch:36 Batch:0\t loss: 0.116758\n",
      "Epoch:36 Batch:500\t loss: 0.118790\n",
      "Epoch:36 Batch:1000\t loss: 0.042161\n",
      "Epoch:36 Batch:1500\t loss: 0.069138\n",
      "Epoch:36 Batch:2000\t loss: 0.079883\n",
      "Epoch:36 Batch:2500\t loss: 0.167141\n",
      "Epoch:36 Batch:3000\t loss: 0.064698\n",
      "Epoch:37 Batch:0\t loss: 0.053295\n",
      "Epoch:37 Batch:500\t loss: 0.044585\n",
      "Epoch:37 Batch:1000\t loss: 0.071514\n",
      "Epoch:37 Batch:1500\t loss: 0.105324\n",
      "Epoch:37 Batch:2000\t loss: 0.066665\n",
      "Epoch:37 Batch:2500\t loss: 0.191149\n",
      "Epoch:37 Batch:3000\t loss: 0.103929\n",
      "Epoch:38 Batch:0\t loss: 0.065797\n",
      "Epoch:38 Batch:500\t loss: 0.158467\n",
      "Epoch:38 Batch:1000\t loss: 0.089855\n",
      "Epoch:38 Batch:1500\t loss: 0.107580\n",
      "Epoch:38 Batch:2000\t loss: 0.082691\n",
      "Epoch:38 Batch:2500\t loss: 0.121257\n",
      "Epoch:38 Batch:3000\t loss: 0.125501\n",
      "Epoch:39 Batch:0\t loss: 0.055925\n",
      "Epoch:39 Batch:500\t loss: 0.031531\n",
      "Epoch:39 Batch:1000\t loss: 0.022893\n",
      "Epoch:39 Batch:1500\t loss: 0.131783\n",
      "Epoch:39 Batch:2000\t loss: 0.061050\n",
      "Epoch:39 Batch:2500\t loss: 0.079240\n",
      "Epoch:39 Batch:3000\t loss: 0.196807\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "train_samples, test_samples = [], []\n",
    "\n",
    "if DO_NSP_TEST :\n",
    "    train_samples, test_samples = train_test_split(all_samples, test_size=0.2, random_state=42)\n",
    "else :\n",
    "    train_samples = all_samples\n",
    "\n",
    "batch_data = make_data(extent_token_list, train_samples, object2idx, n_data=len(all_samples))\n",
    "\n",
    "batch_tensor = [torch.LongTensor(ele) for ele in zip(*batch_data)]\n",
    "dataset = BERTDataset(*batch_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "model = BERT(n_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "model.to(device)\n",
    "\n",
    "print('Entering training process...')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    bat = 0\n",
    "    for one_batch in dataloader:\n",
    "        input_ids, segment_ids, masked_tokens, masked_pos, is_next = [ele.to(device) for ele in one_batch]\n",
    "\n",
    "        logits_cls, logits_lm, _ = model(input_ids, segment_ids, masked_pos)\n",
    "\n",
    "        loss_cls = criterion(logits_cls, is_next)\n",
    "        loss_lm = criterion(logits_lm.view(-1, max_vocab), masked_tokens.view(-1))\n",
    "        loss_lm = (loss_lm.float()).mean()\n",
    "        loss = loss_cls + loss_lm\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # print(f'Epoch:{epoch + 1} \\t loss: {loss:.6f}')\n",
    "    \n",
    "    # 每30个epoch保存一次模型\n",
    "        if bat % 500 == 0 :\n",
    "            print(f'Epoch:{epoch} Batch:{bat}\\t loss: {loss:.6f}')\n",
    "            torch.save(model.state_dict(), 'oo_no_pos_pretrained.dat')\n",
    "        bat += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d56dd2-3618-450c-9225-04674cfc2eb7",
   "metadata": {},
   "source": [
    "# Neighboring Concept Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "18dc99ff-c7e1-456e-a3f9-922e86485bec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True: 0\n",
      "Number of False: 0\n"
     ]
    }
   ],
   "source": [
    "labels = [sample[2] for sample in test_samples]\n",
    "# print(labels)\n",
    "\n",
    "num_true = labels.count(True)\n",
    "num_false = labels.count(False)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of True:\", num_true)\n",
    "print(\"Number of False:\", num_false)\n",
    "\n",
    "labels_mapping = {\"True\": 1, \"False\": 0}\n",
    "labels_01 = [labels_mapping[str(sample[2])] for sample in test_samples]\n",
    "# print(labels_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "28abb838-fa9d-4e0f-915a-2c0db846b2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.861244019138756\n",
      "Precision: 0.7713004484304933\n",
      "Recall: 0.9608938547486033\n",
      "F1 Score: 0.8557213930348258\n",
      "AUC Score: 0.8737523667048457\n"
     ]
    }
   ],
   "source": [
    "if DO_NSP_TEST :\n",
    "    pretrained_model = BERT(n_layers)\n",
    "    pretrained_model.eval()\n",
    "    pretrained_model.load_state_dict(torch.load('oo_no_pos_pretrained.dat'))\n",
    "    pretrained_model.to(device)\n",
    "\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for sample in test_samples:\n",
    "        index_a = sample[0]\n",
    "        index_b = sample[1]\n",
    "        tokens_a = extent_token_list[index_a]\n",
    "        tokens_b = extent_token_list[index_b]\n",
    "\n",
    "        input_ids = torch.tensor([object2idx['[CLS]']] + tokens_a + [object2idx['[SEP]']] + tokens_b + [object2idx['[SEP]']])\n",
    "        segment_ids = torch.tensor([0 for i in range(\n",
    "                        1 + len(tokens_a) + 1)] + [1 for i in range(1 + len(tokens_b))])\n",
    "        masked_pos = torch.tensor([0 for i in range(\n",
    "                        1 + len(tokens_a) + 1)] + [0 for i in range(1 + len(tokens_b))])\n",
    "        input_ids = torch.LongTensor(input_ids).unsqueeze(0).to(device)\n",
    "        segment_ids = torch.LongTensor(segment_ids).unsqueeze(0).to(device)\n",
    "        masked_pos = torch.LongTensor(masked_pos).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "        logits_cls, _, _ = pretrained_model(input_ids, segment_ids, masked_pos)\n",
    "        cpu = torch.device('cpu')\n",
    "        pred_next = logits_cls.data.max(1)[1].data.to(cpu).numpy()[0]\n",
    "        predictions.append(pred_next) \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels_01, predictions)\n",
    "    precision = precision_score(labels_01, predictions)\n",
    "    recall = recall_score(labels_01, predictions)\n",
    "    f1 = f1_score(labels_01, predictions)\n",
    "    roc_auc = roc_auc_score(labels_01, predictions)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"AUC Score:\", roc_auc)\n",
    "else :\n",
    "    print('NSP TEST is disabled since DO_NSP_TEST is set to False.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40256c64-5c39-4e0d-8c3f-7e9e294f2bcc",
   "metadata": {},
   "source": [
    "# Fine-Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7ec4a-ee80-4db1-8e40-e57e1e780117",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe06b24e-1cd3-4a63-879c-eec2a1fc44f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "[     0.      0.  63412. 173808.]\n",
      "[     0.      0.  98918. 275126.]\n",
      "[0 1 2 3]\n",
      "[0.0, 0.0, 0.25950125708939953, 0.7404987429106005]\n",
      "1.0\n",
      "[0.         0.         0.25950126 0.74049874]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def get_true_permutes(extent_token_list, tup_len = 3) :\n",
    "    true_permutes = []\n",
    "    dist = [0 for i in range(tup_len + 1)]\n",
    "    \n",
    "    for extent in extent_token_list :\n",
    "        extent_len = len(extent)\n",
    "        \n",
    "        for now_len in range(2, tup_len + 1) :\n",
    "            if extent_len >= now_len :\n",
    "                now_pmt = [' '.join([str(ele) for ele in list(p)] + ['0' for _ in range(tup_len - now_len)]) for p in itertools.combinations(extent, now_len)]\n",
    " #               now_pmt = [' '.join([str(ele) for ele in list(p)] + ['0' for _ in range(tup_len - now_len)]) for p in itertools.permutations(extent, now_len)]\n",
    "            else :\n",
    "                now_pmt = []\n",
    "                \n",
    "            true_permutes.extend(now_pmt)\n",
    "            dist[now_len] += len(now_pmt)\n",
    "\n",
    "    true_permutes = set(true_permutes)\n",
    "    \n",
    "    return true_permutes, np.array(dist, dtype = np.float64)\n",
    "\n",
    "def pad_negative_samples(object2idx, true_permutes, length_distribution, number) :\n",
    "    lengths = np.arange(0, len(length_distribution))\n",
    "    tup_len = len(length_distribution) - 1 \n",
    "\n",
    "    print(lengths)\n",
    "    print(length_distribution)\n",
    "    print(np.sum(length_distribution))\n",
    "    \n",
    "    length_distribution[-1] = 1.0 - np.sum(length_distribution[0:-1])\n",
    "    length_distribution /= np.sum(length_distribution)\n",
    "    \n",
    "    print(length_distribution)\n",
    "    print(np.sum(length_distribution))\n",
    "    \n",
    "    object_list = []\n",
    "    for obj in object2idx :\n",
    "        if not '[' in obj :\n",
    "            object_list.append(object2idx[obj])\n",
    "    \n",
    "    negative_samples = []\n",
    "    while len(negative_samples) < number :\n",
    "        length = np.random.choice(lengths, p=length_distribution)\n",
    "\n",
    "        tmp_list = random.sample(object_list, length)\n",
    "        if length < tup_len :\n",
    "            tmp_list.extend([0 for _ in range(tup_len - length)])\n",
    "        \n",
    "        tmp_str = ' '.join([str(x) for x in tmp_list])\n",
    "        if tmp_str in true_permutes :\n",
    "            continue\n",
    "\n",
    "        negative_samples.append((tmp_list, False))\n",
    "    return negative_samples\n",
    "\n",
    "def prepare_object_list_data(object2idx, extent_token_list, extent_token_list_new, tup_len = 3) :\n",
    "    old_true_permutes, old_distribution = get_true_permutes(extent_token_list, tup_len)\n",
    "    new_true_permutes, new_distribution = get_true_permutes(extent_token_list_new, tup_len)\n",
    "    added_true_permutes = new_true_permutes - old_true_permutes\n",
    "    added_distribution = new_distribution - old_distribution\n",
    "    added_distribution /= np.sum(added_distribution)\n",
    "    \n",
    "    print(old_distribution)\n",
    "    print(new_distribution)\n",
    "    \n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "    \n",
    "    for perm_str in old_true_permutes :\n",
    "        lst = [int(x) for x in perm_str.split(' ')]\n",
    "        train_samples.append((lst, True))\n",
    "    for perm_str in added_true_permutes :\n",
    "        lst = [int(x) for x in perm_str.split(' ')]\n",
    "        test_samples.append((lst, True))\n",
    "    \n",
    "    train_len = len(train_samples)\n",
    "    test_len = len(test_samples)\n",
    "    \n",
    "    negative_samples = pad_negative_samples(object2idx, new_true_permutes, list(added_distribution), train_len + test_len)\n",
    "    train_negative_samples, test_negative_samples = train_test_split(negative_samples, test_size=test_len / (train_len + test_len), random_state=42)\n",
    "\n",
    "    train_samples.extend(train_negative_samples)\n",
    "    test_samples.extend(test_negative_samples)\n",
    "    \n",
    "    random.shuffle(train_samples)\n",
    "    random.shuffle(test_samples)\n",
    "    \n",
    "    return train_samples, test_samples\n",
    "\n",
    "max_lenn = 0\n",
    "for extent in extent_token_list :\n",
    "    max_lenn = max(max_lenn, len(extent))\n",
    "print(max_lenn)\n",
    "\n",
    "train_labeled_lists, test_labeled_lists = prepare_object_list_data(object2idx, extent_token_list, extent_token_list_new, tup_len = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "444363be-08e7-43c5-9c40-b38c8e7a39b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in test set ratio of 0s: 0.500\n",
      "in test set ratio of 1s: 0.500\n",
      "in train set ratio of 0s: 0.500\n",
      "in train set ratio of 1s: 0.500\n",
      "train set size 261084\n",
      "test set size 93214\n"
     ]
    }
   ],
   "source": [
    "# check the ratio of 1 and 0\n",
    "df = pd.DataFrame(test_labeled_lists, columns=['Pair', 'Label'])\n",
    "\n",
    "# Calculate the ratios\n",
    "ratio_zeros = (df['Label'] == 0).mean()\n",
    "ratio_ones = (df['Label'] == 1).mean()\n",
    "\n",
    "print(f\"in test set ratio of 0s: {ratio_zeros:.3f}\")\n",
    "print(f\"in test set ratio of 1s: {ratio_ones:.3f}\")\n",
    "\n",
    "df2 = pd.DataFrame(train_labeled_lists, columns=['Pair', 'Label'])\n",
    "\n",
    "# Calculate the ratios\n",
    "ratio_zero = (df2['Label'] == 0).mean()\n",
    "ratio_one = (df2['Label'] == 1).mean()\n",
    "\n",
    "print(f\"in train set ratio of 0s: {ratio_zero:.3f}\")\n",
    "print(f\"in train set ratio of 1s: {ratio_one:.3f}\")\n",
    "\n",
    "print('train set size ' + str(len(train_labeled_lists)))\n",
    "print('test set size ' + str(len(test_labeled_lists)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44006f7b-b58f-43b5-ba7b-32dc2ce5e780",
   "metadata": {},
   "source": [
    "## Fine-Tune Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef9943-2c2e-4e63-9d0e-4d98973caddb",
   "metadata": {},
   "source": [
    "##  MLP for classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f9da990-44e9-426a-aa85-dd26c9c29aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# design a MLP for classification task\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, bert_model, embedding_size, hidden_size, output_size, dropout_rate = .1):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.bert = bert_model\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs, segments, masked_poses):\n",
    "        _, __, x = self.bert(inputs, segments, masked_poses)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "def prepare_data(pair_set):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for lst, label in pair_set:\n",
    "        inputs.append(lst)\n",
    "        labels.append(label)\n",
    "    return torch.tensor(inputs), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d50d109-a6e5-41c6-a451-43391b326a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "# input_size = 2 * d_model\n",
    "hidden_size = 324\n",
    "output_size = 1\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 5\n",
    "batch_size = 44\n",
    "\n",
    "pretrained_model = BERT(n_layers)\n",
    "pretrained_model.load_state_dict(torch.load('oo_no_pos_pretrained.dat'))\n",
    "pretrained_model.train()\n",
    "# pretrained_model.eval()\n",
    "pretrained_model.to(device)\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "MLP_model = MLP(pretrained_model, d_model, hidden_size, output_size, dropout_rate=0.1)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(MLP_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Move model to device\n",
    "MLP_model = MLP_model.to(device)\n",
    "MLP_model.train()\n",
    "\n",
    "# Prepare the data\n",
    "train_inputs, train_labels = prepare_data(train_labeled_lists)\n",
    "test_inputs, test_labels = prepare_data(test_labeled_lists)\n",
    "\n",
    "train_inputs, train_labels = train_inputs.to(device), train_labels.to(device)\n",
    "test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a76fa74-69ff-4214-b7da-94c646012c73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|███████████████████████████████████████████████████████| 5934/5934 [07:47<00:00, 12.70it/s, loss=0.335]\n",
      "Epoch 2/5: 100%|████████████████████████████████████████████████████████| 5934/5934 [07:46<00:00, 12.72it/s, loss=0.02]\n",
      "Epoch 3/5: 100%|██████████████████████████████████████████████████████| 5934/5934 [07:47<00:00, 12.70it/s, loss=0.0927]\n",
      "Epoch 4/5: 100%|███████████████████████████████████████████████████████| 5934/5934 [07:48<00:00, 12.67it/s, loss=0.104]\n",
      "Epoch 5/5: 100%|█████████████████████████████████████████████████████| 5934/5934 [07:47<00:00, 12.69it/s, loss=0.00213]\n"
     ]
    }
   ],
   "source": [
    "MLP_model.train()\n",
    "MLP_model.bert.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Create tqdm progress bar\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', dynamic_ncols=True)\n",
    "\n",
    "    for inputs, labels in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        segments = torch.tensor([[0 for _ in i] for i in inputs])\n",
    "        masked_poses = torch.tensor([[0 for _ in range(max_pred)] for i in inputs])\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        segments, masked_poses = segments.to(device), masked_poses.to(device)\n",
    "        \n",
    "        outputs = MLP_model(inputs, segments, masked_poses)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update tqdm with the current loss\n",
    "        pbar.set_postfix(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "41da226b-719b-4e80-bb99-df7a4369c5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(MLP_model.state_dict(), 'MLP.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576624d-bdf2-4f5a-bf23-d3a1e5d82564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "# ... (previous code)\n",
    "MLP_model.eval()\n",
    "MLP_model.bert.eval()\n",
    "MLP_model.to(device)\n",
    "\n",
    "segments = torch.tensor([[0 for _ in i] for i in test_inputs])\n",
    "masked_poses = torch.tensor([[0 for _ in range(max_pred)] for i in test_inputs])\n",
    "\n",
    "segments = segments.to(device)\n",
    "masked_poses = masked_poses.to(device)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    test_outputs = MLP_model(test_inputs, segments, masked_poses)\n",
    "    predictions = (test_outputs > 0.06).float().cpu().numpy()\n",
    "    test_labels_numpy = test_labels.cpu().numpy()\n",
    "\n",
    "# Convert predictions to binary (0 or 1)\n",
    "predictions_binary = (predictions > 0.06).astype(int)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(test_labels_numpy, predictions_binary)\n",
    "precision = precision_score(test_labels_numpy, predictions_binary)\n",
    "recall = recall_score(test_labels_numpy, predictions_binary)\n",
    "f1 = f1_score(test_labels_numpy, predictions_binary)\n",
    "auc = roc_auc_score(test_labels_numpy, test_outputs.cpu().numpy())\n",
    "aupr = average_precision_score(test_labels_numpy, test_outputs.cpu().numpy())\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'AUC: {auc:.4f}')\n",
    "print(f'AUPR: {aupr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1902a30f-23bd-4f69-839b-ec7fa434fc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
